{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from NASmodels import NASController, MasterModel\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fca946d31d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "'hidden_to_embedding.weight',\n",
    "'GRU.weight_ih',\n",
    "'GRU.weight_hh',\n",
    "'GRU.bias_ih',\n",
    "'GRU.bias_hh',\n",
    "'embed.weight',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sizes = []\n",
    "for param_group in params:\n",
    "    param_set = controller.state_dict()[param_group]\n",
    "    param_sizes.append(param_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([14, 488]),\n",
       " torch.Size([1464, 256]),\n",
       " torch.Size([1464, 488]),\n",
       " torch.Size([1464]),\n",
       " torch.Size([1464]),\n",
       " torch.Size([14, 256])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller1 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller2 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller3 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller4 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller5 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller6 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller7 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller8 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller9 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller10 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller11 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller12 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller13 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller14 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller15 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller16 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller17 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)\n",
    "controller18 = NASController(max_len=20, hidden_size=488, embedding_size=256, search_space = model.search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [controller1, controller2, controller3, controller4, controller5, controller6, controller7, controller8, controller9, controller10, controller11, controller12, controller13, controller14, controller15, controller16, controller17, controller18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dict_list = [{} for _ in range(len(model_list))]\n",
    "for param_group in params:\n",
    "    # Concat the parameter tensors at dim=0\n",
    "    param_tensor = torch.cat([model.state_dict()[param_group].unsqueeze(0) for model in model_list], dim=0)\n",
    "    \n",
    "    # Estimate the diagonal of the covariance matrix, and the mean\n",
    "    # WARNING: when the number of selected models becomes large, i worry about numerical stability\n",
    "    unbiased_cov_estimate = cov_diag(param_tensor)\n",
    "    mean_estimates = param_tensor.mean(dim=0)\n",
    "    \n",
    "    # get our new distribution and sample from it to get new models - loc is mean / scale is std\n",
    "    dist = torch.distributions.normal.Normal(loc=mean_estimates, scale=unbiased_cov_estimate)\n",
    "    new_weights = dist.sample((len(module_list),))\n",
    "    \n",
    "    # accumulate the update dictionaries\n",
    "    for i in range(len(model_list)):\n",
    "        update_dict_list[i][param_group] = new_weights[i]\n",
    "\n",
    "# perform the update\n",
    "for model, update_dict in zip(model_list, update_dict_list):\n",
    "    model.load_state_dict(update_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControllerSettings(object):\n",
    "    def __init__(\n",
    "        self, \n",
    "        search_space,\n",
    "        max_len=20,\n",
    "        hidden_size=488,\n",
    "        embedding_size=256,\n",
    "        learning_rate = 1e-5,\n",
    "        device = 'cpu'\n",
    "    ):\n",
    "        self.search_space = search_space\n",
    "        self.max_len = max_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_settings = ControllerSettings(device='cuda:0', search_space = MasterModel(keys=[]).search_space, max_len=20, hidden_size=488, embedding_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_params = []\n",
    "for param_group in NASController(cont_settings).state_dict().keys():\n",
    "    if 'search_space' not in param_group:\n",
    "        controller_params.append(param_group)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_list = [NASController(cont_settings) for _ in range(10)]\n",
    "\n",
    "for model in model_list:\n",
    "    model.register_buffer(param_group.replace('.', '_')+'_means_matrix', torch.ones_like(model.state_dict()[param_group]))\n",
    "    model.register_buffer(param_group.replace('.', '_')+'_cov_matrix', torch.zeros_like(model.state_dict()[param_group]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embed_weight_means_matrix', 'embed_weight_cov_matrix', 'search_space.BN.weight', 'search_space.BN.bias', 'search_space.BN.running_mean', 'search_space.BN.running_var', 'search_space.BN.num_batches_tracked', 'search_space.UpOrDown.Up.weight', 'search_space.UpOrDown.Up.bias', 'search_space.conv11.weight', 'search_space.conv11.bias', 'search_space.conv13.weight', 'search_space.conv13.bias', 'search_space.conv15.weight', 'search_space.conv15.bias', 'search_space.conv3.weight', 'search_space.conv3.bias', 'search_space.conv5.weight', 'search_space.conv5.bias', 'search_space.conv7.weight', 'search_space.conv7.bias', 'search_space.conv9.weight', 'search_space.conv9.bias', 'hidden_to_embedding.weight', 'hidden_to_embedding.bias', 'GRU.weight_ih', 'GRU.weight_hh', 'GRU.bias_ih', 'GRU.bias_hh', 'embed.weight'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[0].state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter \n",
    "class EvolutionController(nn.Module):\n",
    "    def __init__(self, controller_settings, n_models):\n",
    "        super().__init__()\n",
    "        self.controller_settings = controller_settings\n",
    "        self.n_models = n_models\n",
    "        \n",
    "        # Setup initial controller to grab relevant params and shapes for initialization\n",
    "        # should only done once at init\n",
    "        self.controller_params = []\n",
    "        self.cov_matrices = []\n",
    "        self.means_matrices = []\n",
    "        init_state_dict = NASController(controller_settings).state_dict()\n",
    "        for param_group in init_state_dict.keys():\n",
    "            # ignore search space\n",
    "            if 'search_space' not in param_group:\n",
    "                self.controller_params.append(param_group)\n",
    "                # Buffers cannot contain periods. Why? No idea...\n",
    "                self.means_matrices.append(param_group.replace('.', '_') + '_means_matrix')\n",
    "                self.cov_matrices.append(param_group.replace('.', '_') + '_cov_matrix')\n",
    "        \n",
    "        # Since we do not need a separate covariance/means matrix for each model, we instead register them as a buffer in the global scope\n",
    "        # We do this in hopes that it will save to the state_dict, but also in fear that it will double-count ModuleList state_dicts\n",
    "        for param_group, cov_matrix_name, means_matrix_name in zip(self.controller_params, self.cov_matrices, self.means_matrices):\n",
    "            self.register_buffer(cov_matrix_name, torch.ones_like(init_state_dict[param_group]))\n",
    "            self.register_buffer(means_matrix_name, torch.zeros_like(init_state_dict[param_group]))\n",
    "                            \n",
    "        del init_state_dict\n",
    "\n",
    "\n",
    "    def initialize_models(self):        \n",
    "        # initialize update dict that will hold hidden state updates \n",
    "        self.update_dict_list = [{} for _ in range(self.n_models)]\n",
    "        \n",
    "        # initialize models - cant think of better way to store than in ModuleList \n",
    "        # We call no_grad here because we shouldnt anywhere else - we will need grad later, but not here\n",
    "#         with torch.no_grad():\n",
    "        self.model_list = nn.ModuleList([NASController(self.controller_settings) for _ in range(self.n_models)])\n",
    "        \n",
    "        self.evolve_()\n",
    "\n",
    "    def update_cov_matrix_(self, model_list):\n",
    "        for param_group, mean_tensor, cov_tensor in zip(self.controller_params, self.cov_matrices, self.means_matrices):\n",
    "            # Concat the parameter tensors at dim=0\n",
    "            param_tensor = torch.cat([model.state_dict()[param_group].unsqueeze(0) for model in model_list], dim=0)\n",
    "\n",
    "            # Estimate the diagonal of the covariance matrix, and the mean\n",
    "            # WARNING: when the number of selected models becomes large, i worry about numerical stability\n",
    "            unbiased_cov_estimate = cov_diag(param_tensor)\n",
    "            mean_estimates = param_tensor.mean(dim=0)\n",
    "            \n",
    "            # I am missing an embarassing amount of intricacies in the covariance matrix update - way way way off\n",
    "#             step_coef = step_size(n_chosen=5, population_size=25)\n",
    "            step_coef = self.controller_settings.learning_rate\n",
    "            \n",
    "            self.state_dict()[cov_tensor] += step_coef*unbiased_cov_estimate\n",
    "            self.state_dict()[mean_tensor] += step_coef*mean_estimates\n",
    "        \n",
    "        \n",
    "    def evolve_(self):\n",
    "        '''\n",
    "        Pytorch convention is to end any function name with _ if it is an inplace operation\n",
    "        \n",
    "        Notice that this does not take a model_list argument whereas update_cov_matrix does - every population member\n",
    "        will get an update here, whereas when we compute the cov matrix, we are only looking at a subset of the \n",
    "        population\n",
    "        '''\n",
    "        update_dict_list = [{} for _ in range(self.n_models)]\n",
    "        for param_group, mean_tensor, cov_tensor in zip(self.controller_params, self.means_matrices, self.cov_matrices):\n",
    "            dist = torch.distributions.normal.Normal(\n",
    "                loc=self.state_dict()[mean_tensor], \n",
    "                scale=self.state_dict()[cov_tensor]\n",
    "            )\n",
    "            weight_update = dist.sample((self.n_models,))\n",
    "            \n",
    "            # accumulate the update dictionaries\n",
    "            for i in range(self.n_models):\n",
    "                update_dict_list[i][param_group] = weight_update[i]\n",
    "            self.update_dict = self.state_dict()[mean_tensor]\n",
    "        for model, update_dict in zip(self.model_list, update_dict_list):\n",
    "#             self.update_dict = update_dict\n",
    "            model.load_state_dict(update_dict, strict=False)\n",
    "\n",
    "\n",
    "    def forward(self, k):\n",
    "        print('test')\n",
    "        scores = torch.zeros(self.n_models, 2)\n",
    "        # by arbitrary choice, we choose to maximize score\n",
    "        for i, model in enumerate(self.model_list):\n",
    "            scores[i, 0] = 10 - model().good_model\n",
    "            scores[i, 1] = model().dim_change_ops\n",
    "        \n",
    "        survived_indices = torch.topk(scores.sum(axis=1), k=4).indices\n",
    "        \n",
    "        self.update_cov_matrix_(itemgetter(*survived_indices)(self.model_list))\n",
    "\n",
    "        self.evolve_()\n",
    "        print(scores.sum())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "EA = EvolutionController(cont_settings, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "EA.initialize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EA.update_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "tensor(215.)\n"
     ]
    }
   ],
   "source": [
    "EA(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = NASController(cont_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_diag(m):\n",
    "    before = m.shape[1:]\n",
    "    m = m.view(m.size(0), -1)\n",
    "    factor = 1.0 / (m.size(0) - 1)\n",
    "    m -= torch.mean(m, dim=1, keepdim=True)\n",
    "    diag_cov = factor * torch.einsum(\"ij,ij->j\", (m, m))\n",
    "    return diag_cov.view(before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_size(n_chosen, population_size):\n",
    "    return (n_chosen+2)/(population_size+n_chosen+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.999300069993e-05"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size(n_chosen=5, population_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_cov_estimate = cov_diag(Params)\n",
    "mean_estimates = Params.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in params:\n",
    "    controller.state_dict()[param_group] = torch.normal(mean_estimates, unbiased_cov_estimate)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0009)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbiased_cov_estimate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = controller()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-will-gpu] *",
   "language": "python",
   "name": "conda-env-.conda-will-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
