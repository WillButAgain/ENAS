{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_translate(a, Dict):    \n",
    "    return np.vectorize(Dict.__getitem__)(a)\n",
    "\n",
    "class MasterModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, keys, n=32):\n",
    "        super().__init__() \n",
    "        self.input_keys = keys\n",
    "#         self.args = args\n",
    "\n",
    "        \n",
    "        self.UpOrDown = nn.ModuleDict({\n",
    "            'Up':nn.ConvTranspose1d(n, n, kernel_size=2, stride=2),\n",
    "            'Down':nn.MaxPool1d(n)\n",
    "        })\n",
    "        \n",
    "        self.search_space = nn.ModuleDict({\n",
    "            '<SOS>':nn.Identity(),\n",
    "            'conv3':nn.Conv1d(n, n, kernel_size=3, stride=1, padding=(3-1)//2),\n",
    "            'conv5':nn.Conv1d(n, n, kernel_size=5, stride=1, padding=(5-1)//2),\n",
    "            'conv7':nn.Conv1d(n, n, kernel_size=7, stride=1, padding=(7-1)//2),\n",
    "            'conv9':nn.Conv1d(n, n, kernel_size=9, stride=1, padding=(9-1)//2),\n",
    "            'conv11':nn.Conv1d(n, n, kernel_size=11, stride=1, padding=(11-1)//2),\n",
    "            'conv13':nn.Conv1d(n, n, kernel_size=13, stride=1, padding=(13-1)//2),\n",
    "            'conv15':nn.Conv1d(n, n, kernel_size=15, stride=1, padding=(15-1)//2),\n",
    "            'BN':nn.BatchNorm1d(n, n),\n",
    "            'Relu':nn.ReLU(),\n",
    "            'LeakyRelu':nn.LeakyReLU(0.01),\n",
    "            \n",
    "            # Experimental\n",
    "            'Switch':nn.Identity(),\n",
    "            'UpOrDown':self.UpOrDown,\n",
    "\n",
    "            # Should always be at the bottom\n",
    "            '<EOS>':nn.Identity(),\n",
    "        })\n",
    "        self.n_keys = len(self.search_space.keys())+2\n",
    "        \n",
    "        # DO NOT FORGET - you can reference modules in ModuleList by index! \n",
    "        # this is how you will do skip connections later, me!\n",
    "        self.model = nn.ModuleList()\n",
    "        \n",
    "        # we need this defined so it saves to the state_dict\n",
    "        self.initial_conv = nn.Conv1d(1, n, kernel_size=15, padding=(15-1)//2)\n",
    "        self.model.append(self.initial_conv)\n",
    "        \n",
    "        dim_change_op_list = []\n",
    "        dim_change_op = 'Down'\n",
    "        for i, key in enumerate(keys):\n",
    "            if key == 'UpOrDown':\n",
    "                dim_change_op_list.append(dim_change_op)\n",
    "                self.model.append(self.search_space[key][dim_change_op])\n",
    "                continue\n",
    "                \n",
    "            if key == 'Switch':\n",
    "                dim_change_op = 'Up'\n",
    "                continue\n",
    "                \n",
    "            self.model.append(self.search_space[key])        \n",
    "\n",
    "        self.model = nn.Sequential(*self.model)\n",
    "        \n",
    "        # this is going to be the reward mechanism to make sure it doesnt make non-valid autoencoders - AND, if its zero, we know to continue training\n",
    "        self.good_model = 0\n",
    "        for op in dim_change_op_list:\n",
    "            if op == 'Down':\n",
    "                self.good_model += 1\n",
    "            if op == 'Up':\n",
    "                self.good_model -= 1\n",
    "\n",
    "    # DELETE - i do not think this will ever be used\n",
    "    def define_search_space(self, search_space):\n",
    "        self.search_space = search_space\n",
    "        \n",
    "    def save_weights(self):\n",
    "        self.state_dict()['search_space.initial_conv.weight'] = self.state_dict()['initial_conv.weight']\n",
    "        self.state_dict()['search_space.initial_conv.bias'] = self.state_dict()['initial_conv.bias']\n",
    "        \n",
    "        for i, key in enumerate(self.input_keys):\n",
    "            if 'conv' in key:\n",
    "                self.state_dict()['search_space.' + key + '.weight'+'.'+str(i+1)] = self.state_dict()['model.' + str(i+1) + '.weight']\n",
    "                self.state_dict()['search_space.' + key + '.bias'+'.'+str(i+1)] = self.state_dict()['model.' + str(i+1) + '.bias']\n",
    "                print('Updated {} weights'.format('search_space.' + key + '.weight'+'.'+str(i+1)))\n",
    "\n",
    "#         save_dict = {}\n",
    "#         for key in self.state_dict().keys():\n",
    "#             if 'search_space' in key:\n",
    "#                 save_dict[key] = self.state_dict[key]\n",
    "        # fuck it \n",
    "        torch.save(self.state_dict, '/share/lazy/will/ML/RLDatabase/MasterWeights.pyt')\n",
    "\n",
    "        \n",
    "    def load_weights(self):\n",
    "        master_update = torch.load('/share/lazy/will/ML/RLDatabase/MasterWeights.pyt')\n",
    "        \n",
    "        self.state_dict()['initial_conv.weight'] = master_update['search_space.initial_conv.weight']\n",
    "        self.state_dict()['initial_conv.bias'] = master_update['search_space.initial_conv.bias']\n",
    "        \n",
    "        for i, key in enumerate(self.input_keys):\n",
    "            if 'conv' in key:\n",
    "                self.state_dict()['model.' + str(i+1) + '.weight'] = master_update['search_space.' + key + '.weight'+'.'+str(i+1)]\n",
    "                self.state_dict()['model.' + str(i+1) + '.bias'] = master_update['search_space.' + key + '.bias'+'.'+str(i+1)]\n",
    "                print('Updated {} weights'.format('search_space.' + key + '.weight'+'.'+str(i+1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp code to generate the initial weights file - it is initialized as if the nodes are all going to be the same on a per-layer basis\n",
    "init_dict = {}\n",
    "for i in range(10):\n",
    "    for key in model.state_dict().keys():\n",
    "        if 'conv' in key:\n",
    "            init_dict[key +'.'+str(i)] = model.state_dict()[key]\n",
    "torch.save(init_dict, '/share/lazy/will/ML/RLDatabase/MasterWeights.pyt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NASController(nn.Module):\n",
    "    def __init__(self, max_len, search_space, embedding_size=256, hidden_size=488):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_len = max_len\n",
    "        self.search_space = search_space\n",
    "        self.n_keys = len(search_space.keys())\n",
    "        \n",
    "        embedding_size = 256\n",
    "        self.hidden_to_embedding = nn.Linear(hidden_size, self.n_keys)\n",
    "        \n",
    "        self.GRU = nn.GRUCell(\n",
    "            input_size = self.embedding_size,\n",
    "            hidden_size = hidden_size\n",
    "        )\n",
    "        \n",
    "        self.embed = nn.Embedding(\n",
    "            num_embeddings = self.n_keys, \n",
    "            embedding_dim = self.embedding_size, \n",
    "        )\n",
    "\n",
    "        # Initialize hidden states for forward()\n",
    "        self.embedding = torch.zeros((1, self.embedding_size))\n",
    "        self.hidden_state = torch.zeros((1, hidden_size))\n",
    "\n",
    "        self.tokenizer_dict = dict((key, i) for i, key in enumerate(self.search_space.keys()))\n",
    "\n",
    "    def forward(self):\n",
    "        embedding_list = []\n",
    "        for _ in range(self.max_len):\n",
    "            # propagate hidden state\n",
    "            self.hidden_state = self.GRU(self.embedding, self.hidden_state)\n",
    "            predicted_embedding = self.hidden_to_embedding(self.hidden_state)\n",
    "            self.embedding = self.embed(torch.max(predicted_embedding, dim=-1)[1])\n",
    "            embed_index = torch.max(predicted_embedding, dim=-1)[1].item()\n",
    "            if embed_index == self.n_keys-1:\n",
    "                break\n",
    "            embedding_list.append(embed_index)\n",
    "            \n",
    "        model_tokens = self.get_tokens(embedding_list)\n",
    "        return MasterModel(keys=model_tokens)\n",
    "        \n",
    "    \n",
    "\n",
    "    def tokenize(self, input_keys):\n",
    "        return [vec_translate(token, self.tokenizer_dict).tolist() for token in input_keys]\n",
    "\n",
    "    def get_tokens(self, input_indices):\n",
    "        self.get_tokens_dict = dict((v, k) for k, v in self.tokenizer_dict.items())\n",
    "        return [vec_translate(token, self.get_tokens_dict).tolist() for token in input_indices]\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = torch.load('/share/lazy/will/ML/RLDatabase/MasterWeights.pyt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MasterModel(keys=['conv3', 'conv3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.good_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated search_space.conv3.weight.0 weights\n",
      "Updated search_space.conv3.weight.1 weights\n"
     ]
    }
   ],
   "source": [
    "model.update_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = NASController(max_len=20, search_space = model.search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# experimental\n",
    "import hiddenlayer as HL\n",
    "\n",
    "from nni.nas.pytorch import enas\n",
    "from nni.nas.pytorch.callbacks import (ArchitectureCheckpoint,\n",
    "                                       LRSchedulerCallback)\n",
    "\n",
    "from model.collectdata_mdsA import collect_data\n",
    "from model.utilities import Params, start_mlflow_experiment, save_summary\n",
    "from model.NAStrain import EnasTrainer, GeneralNetwork, EnasMutator\n",
    "from model.NASutils import load_full_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Params(64, 200, 0.00001, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'ML'. Detailed error Yaml file '/share/lazy/pv-finder_model_repo/ML/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 197, in list_experiments\n",
      "    experiment = self._get_experiment(exp_id, view_type)\n",
      "  File \"/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py\", line 260, in _get_experiment\n",
      "    meta = read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/mlflow/utils/file_utils.py\", line 167, in read_yaml\n",
      "    raise MissingConfigException(\"Yaml file '%s' does not exist.\" % file_path)\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/share/lazy/pv-finder_model_repo/ML/meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "start_mlflow_experiment('NAS runs', 'pv-finder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded /share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5 in 2.24 s\n",
      "Constructing 64 event dataset took 0.008112 s\n"
     ]
    }
   ],
   "source": [
    "val_loader = collect_data('/share/lazy/sokoloff/ML-data_AA/Oct03_20K_val.h5',\n",
    "                          batch_size=64,\n",
    "                          slice=slice(64),\n",
    "                          masking=True, shuffle=False,\n",
    "                          load_XandXsq=False,\n",
    "                          load_xy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30/2020, 09:39:35 AM] INFO (nni.nas.pytorch.trainer) Epoch 1 Training\n",
      "[07/30/2020, 09:41:58 AM] INFO (nni.nas.pytorch.trainer) Epoch 1 Validating\n",
      "[07/30/2020, 09:41:58 AM] INFO (nni.nas.pytorch.callbacks) Saving architecture to /share/lazy/will/ML/checkpoints/epoch_0.json\n",
      "[07/30/2020, 09:41:58 AM] INFO (nni.nas.pytorch.trainer) Epoch 2 Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/miniconda3/envs/june2020-gpu/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07/30/2020, 09:44:20 AM] INFO (nni.nas.pytorch.trainer) Epoch 2 Validating\n",
      "[07/30/2020, 09:44:20 AM] INFO (nni.nas.pytorch.callbacks) Saving architecture to /share/lazy/will/ML/checkpoints/epoch_1.json\n",
      "[07/30/2020, 09:44:20 AM] INFO (nni.nas.pytorch.trainer) Epoch 3 Training\n",
      "[07/30/2020, 09:46:40 AM] INFO (nni.nas.pytorch.trainer) Epoch 3 Validating\n",
      "[07/30/2020, 09:46:40 AM] INFO (nni.nas.pytorch.callbacks) Saving architecture to /share/lazy/will/ML/checkpoints/epoch_2.json\n",
      "[07/30/2020, 09:46:40 AM] INFO (nni.nas.pytorch.trainer) Epoch 4 Training\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger('nni')\n",
    "log_frequency = 10\n",
    "device = 'cuda:0'\n",
    "\n",
    "model = GeneralNetwork()\n",
    "num_epochs = 1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.05, momentum=0.9, weight_decay=1.0E-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.001)\n",
    "run_name = 'ENAS with jacobian reward RL controller'\n",
    "\n",
    "mutator = EnasMutator(model)\n",
    "# optimizer_to_update = torch.optim.Adam(mutator.parameters(), 1)\n",
    "# Path = '/share/lazy/pv-finder_model_repo/10/162a249aeb354ae8bded6b97d3a4f964/artifacts/mutator_run_stats.pyt'\n",
    "# load_full_state(mutator, optimizer_to_update, Path, freeze_weights=False)\n",
    "\n",
    "with mlflow.start_run(run_name = run_name) as run:\n",
    "\n",
    "    for key, value in vars(args).items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    trainer = EnasTrainer(model,\n",
    "                            mutator = mutator,\n",
    "                            optimizer=optimizer,\n",
    "                            callbacks=[LRSchedulerCallback(lr_scheduler), ArchitectureCheckpoint(\"/share/lazy/will/ML/checkpoints\")],\n",
    "                            batch_size=args.batch_size,\n",
    "                            device = device,\n",
    "                            num_epochs=args.epochs,\n",
    "                            dataloader_train=val_loader,\n",
    "                            dataloader_valid=val_loader,\n",
    "                            mutator_lr = args.lr,\n",
    "                            log_frequency=log_frequency,\n",
    "                         )\n",
    "    \n",
    "    trainer.train()\n",
    "    mlflow.log_artifact('/share/lazy/will/ML/checkpoints/epoch_'+str(args.epochs-1)+'.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "june2020-gpu",
   "language": "python",
   "name": "june2020-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
